{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "train = pd.read_csv('data/Trivago/train.csv', usecols=['session_id', 'timestamp', 'step', 'action_type','reference'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "interaction item image     11860750\nclickout item               1586586\nfilter selection             695917\nsearch for destination       403066\nchange of sort order         400584\ninteraction item info        285402\ninteraction item rating      217246\ninteraction item deals       193794\nsearch for item              152203\nsearch for poi               137444\nName: action_type, dtype: int64"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 3
    }
   ],
   "source": [
    "train.action_type.value_counts()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "# filter 4 behaviors，change of soft order, filter selection, search for destination, search for poi\n",
    "train = train[train['action_type'] != 'change of sort order']\n",
    "train = train[train['action_type'] != 'filter selection']\n",
    "train = train[train['action_type'] != 'search for destination']\n",
    "train = train[train['action_type'] != 'search for poi']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "interaction item image     11860750\nclickout item               1586586\ninteraction item info        285402\ninteraction item rating      217246\ninteraction item deals       193794\nsearch for item              152203\nName: action_type, dtype: int64"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 5
    }
   ],
   "source": [
    "train.action_type.value_counts()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "1649739    7131\n",
      "8796       6348\n",
      "2053822    6044\n",
      "36455      5149\n",
      "104802     4899\n",
      "           ... \n",
      "3166174       1\n",
      "9955578       1\n",
      "1294008       1\n",
      "3366854       1\n",
      "6554458       1\n",
      "Name: reference, Length: 363879, dtype: int64\n",
      "3167404ed3197    3515\n",
      "948641e533837    2811\n",
      "9233fb83c116b    2797\n",
      "191ae48e3cb8e    2647\n",
      "c9b863c921a2d    2601\n",
      "                 ... \n",
      "54d57518b5f71       1\n",
      "f0ab7ac79ffe3       1\n",
      "966ff828dfce8       1\n",
      "67afee1467fd5       1\n",
      "af28a1aeb82ae       1\n",
      "Name: session_id, Length: 885270, dtype: int64\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "print(train.reference.value_counts())\n",
    "print(train.session_id.value_counts())\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "item_supports = train.groupby('reference').size()\n",
    "train = train[np.in1d(train.reference, item_supports[item_supports >=5].index)]\n",
    "\n",
    "session_lengths = train.groupby('session_id').size() \n",
    "train = train[np.in1d(train.session_id, session_lengths[session_lengths>1].index)] \n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# renumber\n",
    "old_itemids = train.reference.unique()\n",
    "old_itemids.sort()\n",
    "new_item_ids = np.arange(1, train.reference.nunique() + 1)\n",
    "itemsid_map = pd.DataFrame({'item_id':old_itemids, 'new_item_id': new_item_ids})\n",
    "train.rename(columns={'reference': 'item_id'}, inplace=True)\n",
    "train = pd.merge(train, itemsid_map, on='item_id' )\n",
    "del(train['item_id'])\n",
    "train.rename(columns={'new_item_id': 'item_Id'}, inplace=True)\n",
    "\n",
    "train.rename(columns={'item_Id': 'item_id'}, inplace=True)\n",
    "\n",
    "def action_id_map(x):\n",
    "    if x == 'clickout item':\n",
    "        return 1\n",
    "    elif x == 'interaction item rating':\n",
    "        return 2\n",
    "    elif x == 'interaction item info':\n",
    "        return 3\n",
    "    elif x == 'interaction item image':\n",
    "        return 4\n",
    "    elif x == 'interaction item deals':\n",
    "        return 5\n",
    "    elif x == 'search for item':\n",
    "        return 6\n",
    "\n",
    "train['action'] = train.action_type.apply(action_id_map)\n",
    "\n",
    "old_sessionids = train.session_id.unique()\n",
    "# old_sessionids.sort()\n",
    "new_session_ids = np.arange(1, train.session_id.nunique() + 1)\n",
    "sessionid_map = pd.DataFrame({'session_id':old_sessionids, 'new_session_id': new_session_ids})\n",
    "train = pd.merge(train, sessionid_map, on='session_id' )\n",
    "del(train['session_id'])\n",
    "train.rename(columns={'new_session_id': 'session_id'}, inplace=True)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# split train, valid and test\n",
    "session_max_time = train.groupby('session_id').timestamp.max()\n",
    "session_max_time.sort_values(inplace=True)\n",
    "session_number = train.session_id.nunique()\n",
    "train_time = session_max_time.values[int(session_number*0.7)]\n",
    "valid_time = session_max_time.values[int(session_number*0.8)]\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_sessions = session_max_time[session_max_time <= train_time].index\n",
    "valid_sessions = session_max_time[(session_max_time > train_time)  & (session_max_time <= valid_time)].index\n",
    "test_sessions = session_max_time[session_max_time > valid_time].index\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_data = train[np.in1d(train.session_id, train_sessions)]\n",
    "valid_data = train[np.in1d(train.session_id, valid_sessions)]\n",
    "test_data = train[np.in1d(train.session_id, test_sessions)]\n",
    "print(len(train_data))\n",
    "print(len(valid_data))\n",
    "print(len(test_data))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(train_data.session_id.value_counts())\n",
    "print(valid_data.session_id.value_counts())\n",
    "print(test_data.session_id.value_counts())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#  save item sequence  and action sequence\n",
    "train_items = train_data.groupby('session_id').item_id.apply(list).tolist()\n",
    "train_actions = train_data.groupby('session_id').action.apply(list).tolist()\n",
    "valid_items = valid_data.groupby('session_id').item_id.apply(list).tolist()\n",
    "valid_actions = valid_data.groupby('session_id').action.apply(list).tolist()\n",
    "test_items = test_data.groupby('session_id').item_id.apply(list).tolist()\n",
    "test_actions = test_data.groupby('session_id').action.apply(list).tolist()\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# filter the last item, generate pos and action_pairs\n",
    "import torch\n",
    "\n",
    "def filter_last_item(all_items_list, all_actions):\n",
    "    new_a = list()\n",
    "    new_actions = list()\n",
    "    for i in range(len(all_items_list)):\n",
    "        item_list = all_items_list[i]\n",
    "        action_list = all_actions[i]\n",
    "        while (len(item_list) > 1) and (item_list[-1] == item_list[-2]):\n",
    "            item_list.pop()\n",
    "            action_list.pop()\n",
    "        if len(item_list) > 1:\n",
    "            new_a.append(item_list)\n",
    "            new_actions.append(action_list)\n",
    "    return new_a, new_actions\n",
    "\n",
    "train_items, train_actions = filter_last_item(train_items, train_actions)\n",
    "valid_items, valid_actions = filter_last_item(valid_items, valid_actions)\n",
    "test_items, test_actions = filter_last_item(test_items, test_actions)\n",
    "        "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# set length = 50\n",
    "new_train_items = []\n",
    "new_valid_items = []\n",
    "new_test_items = []\n",
    "item_dict = dict()\n",
    "item_ctr = 1\n",
    "\n",
    "for item_list in train_items:\n",
    "    new_item_list = []\n",
    "    if len(item_list) > 50:\n",
    "        item_list = item_list[-50:]\n",
    "    for item in item_list:\n",
    "        if item not in item_dict.keys():\n",
    "            item_dict[item] = item_ctr\n",
    "            item_ctr += 1\n",
    "        new_item_list.append(item_dict[item])\n",
    "    for j in range(50 - len(item_list)):\n",
    "        new_item_list.insert(0, 0)\n",
    "    new_train_items.append(new_item_list)\n",
    "        \n",
    "for item_list in valid_items:\n",
    "    new_item_list = []\n",
    "    if len(item_list) > 50:\n",
    "        item_list = item_list[-50:]\n",
    "    for item in item_list:\n",
    "        if item not in item_dict.keys():\n",
    "            item_dict[item] = item_ctr\n",
    "            item_ctr += 1\n",
    "        new_item_list.append(item_dict[item])\n",
    "    for j in range(50 - len(item_list)):\n",
    "        new_item_list.insert(0, 0)\n",
    "    new_valid_items.append(new_item_list)\n",
    "\n",
    "for item_list in test_items:\n",
    "    new_item_list = []\n",
    "    if len(item_list) > 50:\n",
    "        item_list = item_list[-50:]\n",
    "    for item in item_list:\n",
    "        if item not in item_dict.keys():\n",
    "            item_dict[item] = item_ctr\n",
    "            item_ctr += 1\n",
    "        new_item_list.append(item_dict[item])\n",
    "    for j in range(50 - len(item_list)):\n",
    "        new_item_list.insert(0, 0)\n",
    "    new_test_items.append(new_item_list)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def generate_actions_50(all_actions):\n",
    "    new_actions_list = []\n",
    "    for actions in all_actions:\n",
    "        if len(actions) > 50:\n",
    "            actions  = actions[-50:]\n",
    "        new_actions_list.append(actions)\n",
    "    return new_actions_list\n",
    "\n",
    "new_train_actions = generate_actions_50(train_actions)\n",
    "new_valid_actions = generate_actions_50(valid_actions)\n",
    "new_test_actions = generate_actions_50(test_actions)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "max_seqlen = 50\n",
    "def generate_pairs(all_actions):\n",
    "    new_actions = []\n",
    "    all_pairs = []\n",
    "    all_pos = []\n",
    "    pairs_padding = [0 for i in range(max_seqlen)]\n",
    "    for actions in all_actions:\n",
    "        pairs = []\n",
    "        pos = []\n",
    "        for i in range(len(actions)):\n",
    "            pos.append(i+1)\n",
    "        for i in range(len(actions)):\n",
    "            now_a = actions[i] - 1\n",
    "            now_pairs = []\n",
    "            for j in range(len(actions)):\n",
    "                other_a = actions[j]\n",
    "                pair = now_a * 6 + other_a\n",
    "                now_pairs.append(pair)\n",
    "            for j in range(max_seqlen - len(actions)):\n",
    "                now_pairs.insert(0, 0)\n",
    "            pairs.append(now_pairs)\n",
    "        for i in range(max_seqlen-len(actions)):\n",
    "            actions.insert(0, 0)\n",
    "            pos.insert(0, 0)\n",
    "            pairs.insert(0, pairs_padding)\n",
    "        new_actions.append(actions)\n",
    "        all_pos.append(pos)\n",
    "        all_pairs.append(pairs)\n",
    "    return all_pairs, all_pos\n",
    "\n",
    "train_pairs, train_pos = generate_pairs(new_train_actions)\n",
    "valid_pairs, valid_pos = generate_pairs(new_valid_actions)\n",
    "test_pairs, test_pos = generate_pairs(new_test_actions)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import torch\n",
    "data_name = 'Trivago'\n",
    "train_items = torch.LongTensor(new_train_items)\n",
    "valid_items = torch.LongTensor(new_valid_items)\n",
    "test_items = torch.LongTensor(new_test_items)\n",
    "train_actions = torch.LongTensor(new_train_actions)\n",
    "valid_actions = torch.LongTensor(new_valid_actions)\n",
    "test_actions = torch.LongTensor(new_test_actions)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def Construct_connection_matrix(seqs, seq_index, seq_len, actions):\n",
    "    \"\"\"\n",
    "    根据输入序列构造图的边连矩阵\n",
    "    由于内存问题，此处不能进行padding\n",
    "    对于 v1,v2,v3,v2,v1 入度邻接矩阵为：\n",
    "       v1 v2 v3 v2 v1\n",
    "    v1           1\n",
    "    v2 1     1\n",
    "    v3    1\n",
    "    注意，这样的表示方法主要是应为存在重复的边\n",
    "    :param seqs: B，seq\n",
    "    :return: B, seq, seq, 2\n",
    "    \"\"\"\n",
    "    # mask = seqs.gt(0)\n",
    "    items, n_node, A, alias_inputs, seq_real_len, macro_items, micro_actions, micro_actions_len = [], [], [], [], [], [], [], []\n",
    "    num_seqs = seqs.size(0)\n",
    "    # max_n_node = seqs.size(1)\n",
    "    item_seq = seqs.cpu().numpy()\n",
    "    for i in range(num_seqs):\n",
    "        u_input = item_seq[i]\n",
    "        u_index = seq_index[i]\n",
    "        u_seq_len = seq_len[i]\n",
    "        u_actions = actions[i]\n",
    "        u_index = u_index[:u_seq_len.long()] \n",
    "        # seq_index[-1] = seq_index[-2] + 1\n",
    "        u_macro_items = torch.index_select(seqs[i], dim=0, index=u_index.long()) # 得到所有宏观item\n",
    "        u_macro_items = u_macro_items.numpy()\n",
    "        node = np.unique(u_macro_items) \n",
    "        u_A_length = len(node) \n",
    "        u_A_edge = len(u_macro_items) \n",
    "        \n",
    "        items.append(torch.LongTensor(node)) \n",
    "        u_A_in = np.zeros((u_A_length, u_A_edge)) \n",
    "        u_A_out = np.zeros((u_A_length, u_A_edge))\n",
    "        for i in np.arange(len(u_macro_items) - 1): \n",
    "            if u_macro_items[i] == 0:\n",
    "                continue\n",
    "            u = np.where(node == u_macro_items[i])[0][0]\n",
    "            v = np.where(node == u_macro_items[i + 1])[0][0]\n",
    "            u_A_in[v][i] = 1 \n",
    "            u_A_out[u][i] = 1\n",
    "        macro_items.append(torch.LongTensor(u_macro_items))\n",
    "        u_A = np.concatenate([u_A_in, u_A_out])\n",
    "        A.append(torch.LongTensor(u_A))\n",
    "        alias_input = []\n",
    "        for i in u_input:\n",
    "            if i == 0:\n",
    "                continue\n",
    "            else:\n",
    "                alias_input.append(np.where(node == i)[0][0]) \n",
    "        seq_real_len.append(len(alias_input))\n",
    "        alias_inputs.append(torch.LongTensor(alias_input))\n",
    "        u_micro_actions, u_micro_actions_len = seq_action_to_micro_action(u_actions, u_index.long())\n",
    "        micro_actions.append(u_micro_actions)\n",
    "        micro_actions_len.append(u_micro_actions_len)\n",
    "    # B, n_items; B, n_seq; B, n_items, n_edges; B, 1; B, n_edges; B, n_edges, n_micro_actions; B, n_edges, 1\n",
    "    return items, alias_inputs, A, seq_real_len, macro_items, micro_actions, micro_actions_len\n",
    "\n",
    "def seq_action_to_micro_action(actions, seq_index):\n",
    "    seq_len = actions.size(0)\n",
    "    mask = actions.gt(0).float()\n",
    "    real_length = torch.sum(mask).long()\n",
    "    padding_len = seq_len - real_length\n",
    "    last_index = padding_len\n",
    "    micro_actions = []\n",
    "    micro_actions_len = []\n",
    "    for action_index in seq_index:\n",
    "        micro_action = actions[last_index:action_index+1]\n",
    "        last_index = action_index + 1\n",
    "        micro_actions.append(torch.LongTensor(micro_action.long()))\n",
    "        micro_actions_len.append(len(micro_action))\n",
    "    micro_actions_len = torch.LongTensor(micro_actions_len)\n",
    "\n",
    "    return micro_actions, micro_actions_len\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class ListDataset(Dataset):\n",
    "    def __init__(self, *datalist):\n",
    "        assert all(len(datalist[0]) == len(data) for data in datalist)\n",
    "        self.datalist = datalist\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        return tuple(data[index] for data in self.datalist)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.datalist[0])\n",
    "    \n",
    "def batch_padding(batch):\n",
    "    # 根据信息进行padding\n",
    "    # print(len(batch[0]))\n",
    "    item_ids, alias_inputs, A, seq_real_len, macro_items, micro_actions, micro_len, action, pairs, poses, y = zip(*batch)\n",
    "    item_ids = pad_sequence(item_ids, batch_first=True).long()\n",
    "    alias_inputs = pad_sequence(alias_inputs, batch_first=True, padding_value=-1).long()\n",
    "    max_action_len = alias_inputs.size(1)\n",
    "    batch_max_length = item_ids.size(1)\n",
    "    macro_items = pad_sequence(macro_items, batch_first=True, padding_value=0) # n_edges\n",
    "    batch_edge_length = macro_items.size(1)\n",
    "    new_A = []\n",
    "    for a in A:\n",
    "        node_len, edge_len = int(a.size(0)/2), a.size(1)\n",
    "        a_in, a_out = a[:node_len, :], a[node_len:, :]\n",
    "        pad_items_length = batch_max_length - node_len\n",
    "        pad_edges_length = batch_edge_length - edge_len\n",
    "        pad_tuple = (0, pad_edges_length, 0, pad_items_length)\n",
    "        a_in, a_out = F.pad(a_in, pad_tuple), F.pad(a_out, pad_tuple)\n",
    "        new_A.append(torch.cat((a_in, a_out), 1).tolist())\n",
    "    new_micro_actions = []\n",
    "    for ac in micro_actions:\n",
    "        new_ac = pad_sequence(ac, batch_first=True, padding_value=0)\n",
    "        pad_edge_size = batch_edge_length - new_ac.size(0)\n",
    "        pad_action_size = max_action_len - new_ac.size(1)\n",
    "        new_ac = F.pad(new_ac, (0, pad_action_size, 0, pad_edge_size))\n",
    "        new_micro_actions.append(new_ac.tolist())\n",
    "    micro_len = pad_sequence(micro_len, batch_first=True, padding_value=1) # 这里需要注意，padding的内容最后是用不上的\n",
    "    action = pad_sequence(action, batch_first=True)\n",
    "    poses = pad_sequence(poses, batch_first=True)\n",
    "    new_pairs = []\n",
    "    seq_len = action.size(1)\n",
    "    for pair in pairs:\n",
    "        length = pair.size(0)\n",
    "        pad_length = seq_len - length\n",
    "        pad_tuple = (0, pad_length, 0, pad_length)\n",
    "        new_pair = F.pad(pair, pad_tuple)\n",
    "        new_pairs.append(new_pair.tolist())   \n",
    "    return item_ids, alias_inputs, torch.LongTensor(new_A), torch.LongTensor(seq_real_len),torch.LongTensor(macro_items), torch.LongTensor(new_micro_actions), torch.LongTensor(micro_len), action, torch.Tensor(new_pairs), poses, torch.LongTensor(y)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "item_vocab_size = 183561 + 1\n",
    "max_position = 50\n",
    "\n",
    "special_item_index = item_vocab_size \n",
    "train_x_items = train_items[:, :-1]\n",
    "train_x_action = train_actions[:, :]\n",
    "train_x_actions = train_pairs[:, :, :]\n",
    "train_y =  train_items[:, -1]\n",
    "train_pos_x = train_pos[:, :]\n",
    "# train_pos_y = train_pos_t[:, -1]\n",
    "# train_test_length = int(len(test)/3)\n",
    "\n",
    "test_x_items, valid_x_items = test_items[:, :-1], valid_items[:, :-1]\n",
    "test_x_action, valid_x_action = test_actions[:, :], valid_actions[:, :]\n",
    "test_x_actions, valid_x_actions = test_pairs[:, :, :], valid_pairs[:, :, :]\n",
    "test_y, valid_y = test_items[:, -1], valid_items[:, -1]\n",
    "test_pos_x, valid_pos_x = test_pos[:, :], valid_pos[:, :]\n",
    "\n",
    "def get_unique_items(items):\n",
    "    \"\"\"\n",
    "    :param items:  B, L\n",
    "    :return: \n",
    "    \"\"\"\n",
    "    n, length = items.size(0), items.size(1)\n",
    "    items_index, items_len = [], []\n",
    "    for i in range(n):\n",
    "        seq_index = []\n",
    "        for j in range(length-1):\n",
    "            item = items[i][j]\n",
    "            if item == 0 or item == items[i][j+1]:\n",
    "                continue\n",
    "            else:\n",
    "                seq_index.append(j)\n",
    "        seq_index.append(length-1)\n",
    "        items_index.append(torch.Tensor(seq_index))\n",
    "        items_len.append(len(seq_index))\n",
    "    return items_index, torch.LongTensor(items_len)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def re_data(bh_seqs, pos_seqs, pair_seqs):\n",
    "    \"\"\"\n",
    "    :param bh_seqs: |\n",
    "    :param pos_seqs: \n",
    "    :param pair_seqs: \n",
    "    :return: \n",
    "    \"\"\"\n",
    "    seqs_actions = list()\n",
    "    seqs_poses = list()\n",
    "    seqs_pairs = list()\n",
    "    data_len = len(bh_seqs)\n",
    "    for i in range(data_len):\n",
    "        new_seq = list()\n",
    "        new_pos = list()\n",
    "        new_pairs = list()\n",
    "        bh_seq = bh_seqs[i]\n",
    "        pos_seq = pos_seqs[i]\n",
    "        pair_seq = pair_seqs[i]\n",
    "        length = len(bh_seq)\n",
    "        for j in range(length):\n",
    "            action = bh_seq[j]\n",
    "            pos = pos_seq[j]\n",
    "            pair = pair_seq[j]\n",
    "            if action == 0:\n",
    "                continue\n",
    "            else:\n",
    "                new_seq.append(action)\n",
    "                new_pos.append(pos)\n",
    "                new_pair = list()\n",
    "                for pair_content in pair:\n",
    "                    if pair_content == 0:\n",
    "                        continue\n",
    "                    else:\n",
    "                        new_pair.append(pair_content)\n",
    "                new_pairs.append(new_pair)\n",
    "        new_seq, new_pos, new_pairs = reverse_last(new_seq, new_pos, new_pairs)\n",
    "        seqs_actions.append(torch.Tensor(new_seq))\n",
    "        seqs_poses.append(torch.Tensor(new_pos))\n",
    "        seqs_pairs.append(torch.Tensor(new_pairs))\n",
    "    return seqs_actions, seqs_poses, seqs_pairs\n",
    "\n",
    "def reverse_last(one_actions, one_pos, one_pairs):\n",
    "    \"\"\"\n",
    "    :param one_actions: \n",
    "    :param one_pos: \n",
    "    :param one_pairs: \n",
    "    :return: \n",
    "    \"\"\"\n",
    "    last_action = one_actions.pop()\n",
    "    last_pos = one_pos.pop()\n",
    "    new_actions = [last_action] + one_actions\n",
    "    new_pos = [last_pos] + one_pos\n",
    "    new_pairs = []\n",
    "    for pairs in one_pairs:\n",
    "        last_ = pairs.pop()\n",
    "        new_pair = [last_] + pairs\n",
    "        new_pairs.append(new_pair)\n",
    "    last_pair = new_pairs.pop()\n",
    "    new_pairs = [last_pair] + new_pairs\n",
    "    return new_actions, new_pos, new_pairs"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_items_index, train_items_len = get_unique_items(train_x_items)\n",
    "test_items_index, test_items_len = get_unique_items(test_x_items)\n",
    "valid_items_index, valid_items_len = get_unique_items(valid_x_items)\n",
    "train_items_index = pad_sequence(train_items_index, batch_first=True,padding_value=-1)\n",
    "test_items_index = pad_sequence(test_items_index, batch_first=True, padding_value=-1)\n",
    "valid_items_index = pad_sequence(valid_items_index, batch_first=True, padding_value=-1)\n",
    "torch.save(train_items_index, 'data/%s/new_train_items_index.pt' % data_name)\n",
    "torch.save(train_items_len,  'data/%s/new_train_items_len.pt' % data_name)\n",
    "torch.save(test_items_index,  'data/%s/new_test_items_index.pt' % data_name)\n",
    "torch.save(test_items_len,  'data/%s/new_test_items_len.pt' % data_name)\n",
    "torch.save(valid_items_index, 'data/%s/new_valid_items_index.pt' % data_name)\n",
    "torch.save(valid_items_len, 'data/%s/new_valid_items_len.pt' % data_name)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_items, train_alias_inputs, train_A, train_rel_len, train_macro_items, train_micro_actions, train_micro_len = Construct_connection_matrix(train_x_items, train_items_index, train_items_len, train_x_action)\n",
    "train_bh, train_pos, train_pairs = re_data(train_x_action, train_pos_x, train_x_actions)\n",
    "\n",
    "valid_items, valid_alias_inputs, valid_A, valid_rel_len, valid_macro_items, valid_micro_acitons, valid_micro_len = Construct_connection_matrix(valid_x_items, valid_items_index, valid_items_len, valid_x_action)\n",
    "val_bh, val_pos, val_pairs = re_data(valid_x_action, valid_pos_x, valid_x_actions)\n",
    "\n",
    "test_items, test_alias_inputs, test_A, test_rel_len, test_macro_items, test_micro_actions, test_micro_len = Construct_connection_matrix(test_x_items, test_items_index, test_items_len, test_x_action)\n",
    "test_bh, test_pos, test_pairs = re_data(test_x_action, test_pos_x, test_x_actions)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_sets = ListDataset(train_items, train_alias_inputs, train_A, train_rel_len, train_macro_items, train_micro_actions, train_micro_len, train_bh, train_pairs, train_pos, train_y.long())\n",
    "\n",
    "valid_sets = ListDataset(valid_items, valid_alias_inputs, valid_A, valid_rel_len,valid_macro_items, valid_micro_acitons, valid_micro_len, val_bh, val_pairs, val_pos, valid_y.long())\n",
    "\n",
    "test_sets = ListDataset(test_items, test_alias_inputs, test_A, test_rel_len, test_macro_items, test_micro_actions, test_micro_len, test_bh, test_pairs, test_pos,test_y.long())\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "torch.save(train_sets, 'data/%s/train_sets_EMBSR.pt'% data_name)\n",
    "torch.save(valid_sets, 'data/%s/valid_sets_EMBSR.pt'% data_name)\n",
    "torch.save(test_sets, 'data/%s/test_sets_EMBSR.pt'% data_name)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "import torch\n",
    "data_name = 'Trivago'\n",
    "train_sets = torch.load('data/%s/train_sets_EMBSR.pt'% data_name)\n",
    "valid_sets = torch.load('data/%s/valid_sets_EMBSR.pt'% data_name)\n",
    "test_sets = torch.load('data/%s/test_sets_EMBSR.pt'% data_name)\n",
    " "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}